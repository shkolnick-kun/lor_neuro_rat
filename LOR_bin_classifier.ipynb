{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This file is a part of the lor_neuro_rat project.\n",
    "    Copyright (C) 2019 anonimous\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\n",
    "    Please contact with me by E-mail: shkolnick.kun@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(32)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, recall_score, f1_score, accuracy_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv1D, Embedding, SpatialDropout1D, concatenate, Flatten\n",
    "from keras.layers import GRU, LSTM, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, Dropout\n",
    "#from keras.layers import CuDNNLSTM, CuDNNGRU\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "from keras.layers import Lambda\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import os\n",
    "#os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "#from unidecode import unidecode\n",
    "\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сформируем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/XyWrdTok.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   TopId             MsgId                    Creator  \\\n",
      "0  /forum/games/14782451  comment-14783955                              \n",
      "1  /forum/games/14782451  comment-14783416     /people/Quasar/profile   \n",
      "2  /forum/talks/14792750  comment-14796970        /people/dem/profile   \n",
      "3  /forum/talks/14746691  comment-14748059  /people/Nastishka/profile   \n",
      "4  /forum/talks/14708360  comment-14710855     /people/takino/profile   \n",
      "\n",
      "                            Time                             SrcLink  \\\n",
      "0  2019-02-04T15:07:41.843+03:00                                       \n",
      "1  2019-02-04T12:49:45.873+03:00  /forum/games/14782451?cid=14783405   \n",
      "2  2019-02-09T21:48:25.312+03:00  /forum/talks/14792750?cid=14796966   \n",
      "3  2019-01-20T01:02:29.181+03:00  /forum/talks/14746691?cid=14748036   \n",
      "4  2019-01-03T07:58:00.200+03:00                                       \n",
      "\n",
      "                                           DelReason  \\\n",
      "0  Сообщение удалено tailgunner по причине 5.3 На...   \n",
      "1  Сообщение удалено tailgunner по причине 5.2 Ос...   \n",
      "2  Сообщение удалено tailgunner по причине 5.2 Ос...   \n",
      "3  Сообщение удалено tailgunner по причине 5.1; и...   \n",
      "4  Сообщение удалено tailgunner по причине 5.1, х...   \n",
      "\n",
      "                                                 Txt Code  \\\n",
      "0  [Хохлы они и есть хохлы. Игрушка не очень, поэ...   []   \n",
      "1  [А теперь, наркоманыч, Соси пинус., Потому что...   []   \n",
      "2  [Ты дурак, нет ты дурак... Школа... Садик или ...   []   \n",
      "3  [С того, что появится реальная картина того, ч...   []   \n",
      "4  [Васян, у тебя сервис каждые двадцать минут па...   []   \n",
      "\n",
      "                                              Quotes  \\\n",
      "0                                                 []   \n",
      "1  [А теперь, наркоманыч, Потому что с гогом это ...   \n",
      "2                                                 []   \n",
      "3                                                 []   \n",
      "4  [Васян, у тебя сервис каждые двадцать минут па...   \n",
      "\n",
      "                                              Reason  Score  Class  Use  \\\n",
      "0   5.3 Национальные/политические/религиозные спо...     -7     17    1   \n",
      "1          5.2 Оскорбление участников дискуссии (-7)     -7     16    1   \n",
      "2          5.2 Оскорбление участников дискуссии (-1)     -1     16    1   \n",
      "3   5.1; и нет, в КНДР нет даже десятков миллионо...     -2     15    1   \n",
      "4                       5.1, хотя по сути верно (-2)     -2     15    1   \n",
      "\n",
      "                                                Text  \\\n",
      "0  Хохлы они и есть хохлы. Игрушка не очень, поэт...   \n",
      "1  А теперь, наркоманыч Соси пинус. Потому что с ...   \n",
      "2  Ты дурак, нет ты дурак... Школа... Садик или Ясли   \n",
      "3  С того, что появится реальная картина того, чт...   \n",
      "4  Васян, у тебя сервис каждые двадцать минут пад...   \n",
      "\n",
      "                                               Words  WrdCnt  \\\n",
      "0     [хохлы, хохлы, игрушка, очень, поэтому, пофиг]       6   \n",
      "1  [наркоманыч, соси, пинус, гогом, это, именно, ...      27   \n",
      "2                 [дурак, дурак, школа, садик, ясли]       5   \n",
      "3  [появится, реальная, картина, увязка, облака, ...      75   \n",
      "4  [васян, сервис, каждые, двадцать, минут, падае...      32   \n",
      "\n",
      "                                              Tokens  TokCnt  \n",
      "0    [хохол, хохол, игрушка, очень, поэтому, пофига]       6  \n",
      "1  [наркоманыч, сосать, пинус, гог, это, именно, ...      27  \n",
      "2                 [дурак, дурак, школа, садик, ясли]       5  \n",
      "3  [появиться, реальный, картина, увязка, облако,...      74  \n",
      "4  [васян, сервис, каждый, двадцать, минута, пада...      31  \n",
      "              Score         Class           Use        WrdCnt        TokCnt\n",
      "count  46391.000000  46391.000000  46391.000000  46391.000000  46391.000000\n",
      "mean      -0.039318      0.170637      0.012696     21.470285     21.396844\n",
      "std        0.518805      1.543905      0.111962     32.077247     31.949034\n",
      "min      -20.000000      0.000000      0.000000      0.000000      0.000000\n",
      "25%        0.000000      0.000000      0.000000      7.000000      7.000000\n",
      "50%        0.000000      0.000000      0.000000     13.000000     13.000000\n",
      "75%        0.000000      0.000000      0.000000     25.000000     25.000000\n",
      "max        0.000000     17.000000      1.000000   2053.000000   2050.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb426d06c50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.describe())\n",
    "df['TokCnt'].hist(bins=100)\n",
    "df['WrdCnt'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка имбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Use'].values\n",
    "X = [' '.join(tokens) for tokens in list(df['Tokens'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хохол хохол игрушка очень поэтому пофига\n",
      "весь проснуться рая некоторый просто сдохнуть тм\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(X[1000])\n",
    "print(y[0])\n",
    "print(y[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56287\n"
     ]
    }
   ],
   "source": [
    "#Приделываем токенайзер из keras\n",
    "max_features = 100000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(X)\n",
    "print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33403\n"
     ]
    }
   ],
   "source": [
    "wrds = []\n",
    "idxs = []\n",
    "for w, i in tokenizer.word_index.items():\n",
    "    wrds.append(w)\n",
    "    idxs.append(i)\n",
    "    \n",
    "if 'ебаный' in wrds:\n",
    "    print(idxs[wrds.index('ебаный')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохраняем токенайзер\n",
    "with open('models/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Грузим токенайзер\n",
    "with open('models/tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_seq_pad = pad_sequences(X_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"X_seq_pad\": shape (46391, 200), type \"<i4\">\n",
      "<HDF5 dataset \"y\": shape (46391,), type \"<i8\">\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('data/Xy.h5', 'w')\n",
    "print(h5f.create_dataset('X_seq_pad', data=X_seq_pad))\n",
    "print(h5f.create_dataset('y', data=y))\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46391, 200)\n",
      "(46391,)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File('data/Xy.h5', 'r')\n",
    "X_seq_pad = h5f['X_seq_pad'][:]\n",
    "y         = h5f['y'][:]\n",
    "h5f.close()\n",
    "print(X_seq_pad.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56288\n"
     ]
    }
   ],
   "source": [
    "#Вычисляем матрицу весов слоя имбеддингов\n",
    "from pymagnitude import *\n",
    "import gensim\n",
    "\n",
    "mg = Magnitude('Vectors/araneum_none_fasttextskipgram_300_5_2018/araneum_none_fasttextskipgram_300_5_2018.magnitude')\n",
    "ft = gensim.models.fasttext.FastText.load('Vectors/araneum_none_fasttextskipgram_300_5_2018/araneum_none_fasttextskipgram_300_5_2018.model')\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index)+1)\n",
    "embedding_matrix = np.zeros((nb_words,300))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    #\n",
    "    if i >= max_features: \n",
    "        continue\n",
    "    #\n",
    "    #embedding_matrix[i] = mg.query(word)\n",
    "    try:\n",
    "        embedding_matrix[i] = ft.wv[word]\n",
    "    except:\n",
    "        embedding_matrix[i] = mg.query(word)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"EmbeddingMtx\": shape (56288, 300), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "#Сохраняем матрицу имбеддингов\n",
    "h5f = h5py.File('models/EmbeddingMtx.h5', 'w')\n",
    "print(h5f.create_dataset('EmbeddingMtx', data=embedding_matrix))\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Грузим матрицу имбеддингов\n",
    "h5f = h5py.File('models/EmbeddingMtx.h5', 'r')\n",
    "embedding_matrix = h5f['EmbeddingMtx'][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ab69fd91af84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mg' is not defined"
     ]
    }
   ],
   "source": [
    "print(mg.most_similar(embedding_matrix[41]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Взято отсюда: https://www.kaggle.com/larryfreeman/toxic-comments-code-for-alexander-s-9872-model\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1, cv_iter=0, arch=0):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val, self.Weigths = validation_data\n",
    "        self.max_score = 0\n",
    "        self.not_better_count = 0\n",
    "        self._cv_iter = cv_iter\n",
    "        self._arch = arch\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=1, batch_size=512)\n",
    "            score = roc_auc_score(self.y_val, y_pred, sample_weight=self.Weigths)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "            if (score > self.max_score):\n",
    "                print(\"*** New High Score (previous: %.6f) \\n\" % self.max_score)\n",
    "                model.save(\"models/best_model_%d_%d.h5\"%(int(self._arch),int(self._cv_iter)))\n",
    "                self.max_score=score\n",
    "                self.not_better_count = 0\n",
    "            else:\n",
    "                self.not_better_count += 1\n",
    "                if self.not_better_count > 3:\n",
    "                    print(\"Epoch %05d: early stopping, high score = %.6f\" % (epoch,self.max_score))\n",
    "                    self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Взято отсюда: https://www.kaggle.com/larryfreeman/toxic-comments-code-for-alexander-s-9872-model\n",
    "#Model 0\n",
    "nn_arch = 0\n",
    "def get_model(clipvalue=1.,num_filters=40,dropout=0.5,embed_size=300):\n",
    "    inp = Input(shape=(max_len, ))\n",
    "    \n",
    "    # Layer 1: concatenated fasttext and glove twitter embeddings.\n",
    "    x = Embedding(nb_words, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    \n",
    "    # Uncomment for best result\n",
    "    # Layer 2: SpatialDropout1D(0.5)\n",
    "    #x = SpatialDropout1D(dropout)(x)\n",
    "    \n",
    "    # Uncomment for best result\n",
    "    # Layer 3: Bidirectional CuDNNLSTM\n",
    "    #x = Bidirectional(LSTM(num_filters, return_sequences=True))(x)\n",
    "\n",
    "\n",
    "    # Layer 4: Bidirectional CuDNNGRU\n",
    "    x, x_h, x_c = Bidirectional(GRU(num_filters, return_sequences=True, return_state = True))(x)  \n",
    "    \n",
    "    # Layer 5: A concatenation of the last state, maximum pool, average pool and \n",
    "    # two features: \"Unique words rate\" and \"Rate of all-caps words\"\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    x = concatenate([avg_pool, x_h, max_pool])\n",
    "    \n",
    "    # Layer 6: output dense layer.\n",
    "    outp = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    adam = optimizers.adam(clipvalue=clipvalue)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  weighted_metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Взято отсюда: https://www.kaggle.com/larryfreeman/toxic-comments-code-for-alexander-s-9872-model\n",
    "#Model 1\n",
    "nn_arch = 1\n",
    "def get_model(clipvalue=1.,num_filters=40,dropout=0.5,embed_size=300):\n",
    "    inp = Input(shape=(max_len, ))\n",
    "    \n",
    "    # Layer 1: concatenated fasttext and glove twitter embeddings.\n",
    "    x = Embedding(nb_words, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    \n",
    "    # Uncomment for best result\n",
    "    # Layer 2: SpatialDropout1D(0.5)\n",
    "    x = SpatialDropout1D(dropout)(x)\n",
    "    \n",
    "    # Uncomment for best result\n",
    "    # Layer 3: Bidirectional CuDNNLSTM\n",
    "    #x = Bidirectional(LSTM(num_filters, return_sequences=True))(x)\n",
    "\n",
    "\n",
    "    # Layer 4: Bidirectional CuDNNGRU\n",
    "    x, x_h, x_c = Bidirectional(GRU(num_filters, return_sequences=True, return_state = True))(x)  \n",
    "    \n",
    "    # Layer 5: A concatenation of the last state, maximum pool, average pool and \n",
    "    # two features: \"Unique words rate\" and \"Rate of all-caps words\"\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    x = concatenate([avg_pool, x_h, max_pool])\n",
    "    \n",
    "    # Layer 6: output dense layer.\n",
    "    outp = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    adam = optimizers.adam(clipvalue=clipvalue)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  weighted_metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Взято отсюда: https://www.kaggle.com/larryfreeman/toxic-comments-code-for-alexander-s-9872-model\n",
    "#Model 2\n",
    "nn_arch = 2\n",
    "def get_model(clipvalue=1.,num_filters=40,dropout=0.5,embed_size=300):\n",
    "    inp = Input(shape=(max_len, ))\n",
    "    \n",
    "    # Layer 1: concatenated fasttext and glove twitter embeddings.\n",
    "    x = Embedding(nb_words, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    \n",
    "    # Uncomment for best result\n",
    "    # Layer 2: SpatialDropout1D(0.5)\n",
    "    x = SpatialDropout1D(dropout)(x)\n",
    "    \n",
    "    # Uncomment for best result\n",
    "    # Layer 3: Bidirectional CuDNNLSTM\n",
    "    x = Bidirectional(LSTM(num_filters, return_sequences=True))(x)\n",
    "\n",
    "\n",
    "    # Layer 4: Bidirectional CuDNNGRU\n",
    "    x, x_h, x_c = Bidirectional(GRU(num_filters, return_sequences=True, return_state = True))(x)  \n",
    "    \n",
    "    # Layer 5: A concatenation of the last state, maximum pool, average pool and \n",
    "    # two features: \"Unique words rate\" and \"Rate of all-caps words\"\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    x = concatenate([avg_pool, x_h, max_pool])\n",
    "    \n",
    "    # Layer 6: output dense layer.\n",
    "    outp = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    adam = optimizers.adam(clipvalue=clipvalue)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  weighted_metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3\n",
    "nn_arch = 3\n",
    "def get_model(clipvalue=1.,num_filters=40,dropout=0.5,embed_size=300):\n",
    "    inp = Input(shape=(max_len, ))\n",
    "    \n",
    "    # Layer 1: concatenated fasttext and glove twitter embeddings.\n",
    "    x = Embedding(nb_words, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    \n",
    "    x = Dense(num_filters, activation=\"relu\")(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    # Layer 6: output dense layer.\n",
    "    outp = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    adam = optimizers.adam(clipvalue=clipvalue)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  weighted_metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 1\n",
      "Epoch 1/100\n",
      "34793/34793 [==============================] - 22s 633us/step - loss: 0.6637 - weighted_acc: 0.5737\n",
      "11598/11598 [==============================] - 3s 231us/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.728828 \n",
      "\n",
      "*** New High Score (previous: 0.000000) \n",
      "\n",
      "Epoch 2/100\n",
      "34793/34793 [==============================] - 21s 593us/step - loss: 0.6168 - weighted_acc: 0.6569\n",
      "11598/11598 [==============================] - 3s 218us/step\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.763747 \n",
      "\n",
      "*** New High Score (previous: 0.728828) \n",
      "\n",
      "Epoch 3/100\n",
      "34793/34793 [==============================] - 21s 594us/step - loss: 0.5904 - weighted_acc: 0.6732\n",
      "11598/11598 [==============================] - 3s 229us/step\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.790178 \n",
      "\n",
      "*** New High Score (previous: 0.763747) \n",
      "\n",
      "Epoch 4/100\n",
      "34793/34793 [==============================] - 21s 618us/step - loss: 0.5597 - weighted_acc: 0.6956\n",
      "11598/11598 [==============================] - 3s 236us/step\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.801606 \n",
      "\n",
      "*** New High Score (previous: 0.790178) \n",
      "\n",
      "Epoch 5/100\n",
      "34793/34793 [==============================] - 21s 599us/step - loss: 0.5359 - weighted_acc: 0.7266\n",
      "11598/11598 [==============================] - 3s 220us/step\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.806611 \n",
      "\n",
      "*** New High Score (previous: 0.801606) \n",
      "\n",
      "Epoch 6/100\n",
      "34793/34793 [==============================] - 21s 598us/step - loss: 0.5186 - weighted_acc: 0.7392\n",
      "11598/11598 [==============================] - 3s 220us/step\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.809151 \n",
      "\n",
      "*** New High Score (previous: 0.806611) \n",
      "\n",
      "Epoch 7/100\n",
      "34793/34793 [==============================] - 21s 601us/step - loss: 0.5139 - weighted_acc: 0.7384\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.811712 \n",
      "\n",
      "*** New High Score (previous: 0.809151) \n",
      "\n",
      "Epoch 8/100\n",
      "34793/34793 [==============================] - 21s 596us/step - loss: 0.5029 - weighted_acc: 0.7497\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.814398 \n",
      "\n",
      "*** New High Score (previous: 0.811712) \n",
      "\n",
      "Epoch 9/100\n",
      "34793/34793 [==============================] - 21s 597us/step - loss: 0.4828 - weighted_acc: 0.7471\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.816445 \n",
      "\n",
      "*** New High Score (previous: 0.814398) \n",
      "\n",
      "Epoch 10/100\n",
      "34793/34793 [==============================] - 21s 597us/step - loss: 0.4785 - weighted_acc: 0.7680\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.815823 \n",
      "\n",
      "Epoch 11/100\n",
      "34793/34793 [==============================] - 21s 599us/step - loss: 0.4657 - weighted_acc: 0.7778\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.811895 \n",
      "\n",
      "Epoch 12/100\n",
      "34793/34793 [==============================] - 21s 599us/step - loss: 0.4554 - weighted_acc: 0.7772\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.808638 \n",
      "\n",
      "Epoch 13/100\n",
      "34793/34793 [==============================] - 21s 597us/step - loss: 0.4398 - weighted_acc: 0.7987\n",
      "11598/11598 [==============================] - 3s 220us/step\n",
      "\n",
      " ROC-AUC - epoch: 13 - score: 0.798049 \n",
      "\n",
      "Epoch 00012: early stopping, high score = 0.816445\n",
      "Epoch 1/100\n",
      "34793/34793 [==============================] - 22s 640us/step - loss: 0.6806 - weighted_acc: 0.5823\n",
      "11598/11598 [==============================] - 3s 240us/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.723853 \n",
      "\n",
      "*** New High Score (previous: 0.000000) \n",
      "\n",
      "Epoch 2/100\n",
      "34793/34793 [==============================] - 21s 611us/step - loss: 0.6237 - weighted_acc: 0.6841\n",
      "11598/11598 [==============================] - 3s 224us/step\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.748577 \n",
      "\n",
      "*** New High Score (previous: 0.723853) \n",
      "\n",
      "Epoch 3/100\n",
      "34793/34793 [==============================] - 21s 606us/step - loss: 0.5770 - weighted_acc: 0.7192\n",
      "11598/11598 [==============================] - 3s 226us/step\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.765311 \n",
      "\n",
      "*** New High Score (previous: 0.748577) \n",
      "\n",
      "Epoch 4/100\n",
      "34793/34793 [==============================] - 21s 616us/step - loss: 0.5623 - weighted_acc: 0.7314\n",
      "11598/11598 [==============================] - 3s 224us/step\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.780245 \n",
      "\n",
      "*** New High Score (previous: 0.765311) \n",
      "\n",
      "Epoch 5/100\n",
      "34793/34793 [==============================] - 21s 597us/step - loss: 0.5378 - weighted_acc: 0.7383\n",
      "11598/11598 [==============================] - 3s 223us/step\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.782441 \n",
      "\n",
      "*** New High Score (previous: 0.780245) \n",
      "\n",
      "Epoch 6/100\n",
      "34793/34793 [==============================] - 21s 602us/step - loss: 0.5336 - weighted_acc: 0.7404\n",
      "11598/11598 [==============================] - 3s 220us/step\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.787126 \n",
      "\n",
      "*** New High Score (previous: 0.782441) \n",
      "\n",
      "Epoch 7/100\n",
      "34793/34793 [==============================] - 21s 595us/step - loss: 0.5131 - weighted_acc: 0.7549\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.789733 \n",
      "\n",
      "*** New High Score (previous: 0.787126) \n",
      "\n",
      "Epoch 8/100\n",
      "34793/34793 [==============================] - 21s 605us/step - loss: 0.4890 - weighted_acc: 0.7718\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.790094 \n",
      "\n",
      "*** New High Score (previous: 0.789733) \n",
      "\n",
      "Epoch 9/100\n",
      "34793/34793 [==============================] - 21s 598us/step - loss: 0.4874 - weighted_acc: 0.7797\n",
      "11598/11598 [==============================] - 3s 225us/step\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.790495 \n",
      "\n",
      "*** New High Score (previous: 0.790094) \n",
      "\n",
      "Epoch 10/100\n",
      "34793/34793 [==============================] - 21s 602us/step - loss: 0.4627 - weighted_acc: 0.7978\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.789806 \n",
      "\n",
      "Epoch 11/100\n",
      "34793/34793 [==============================] - 21s 599us/step - loss: 0.4661 - weighted_acc: 0.7990\n",
      "11598/11598 [==============================] - 3s 220us/step\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.790264 \n",
      "\n",
      "Epoch 12/100\n",
      "34793/34793 [==============================] - 21s 598us/step - loss: 0.4445 - weighted_acc: 0.8022\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.781101 \n",
      "\n",
      "Epoch 13/100\n",
      "34793/34793 [==============================] - 21s 598us/step - loss: 0.4365 - weighted_acc: 0.8079\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 13 - score: 0.782164 \n",
      "\n",
      "Epoch 00012: early stopping, high score = 0.790495\n",
      "Epoch 1/100\n",
      "34793/34793 [==============================] - 22s 626us/step - loss: 0.6816 - weighted_acc: 0.5815\n",
      "11598/11598 [==============================] - 3s 235us/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.775640 \n",
      "\n",
      "*** New High Score (previous: 0.000000) \n",
      "\n",
      "Epoch 2/100\n",
      "34793/34793 [==============================] - 21s 596us/step - loss: 0.6314 - weighted_acc: 0.6583\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.795600 \n",
      "\n",
      "*** New High Score (previous: 0.775640) \n",
      "\n",
      "Epoch 3/100\n",
      "34793/34793 [==============================] - 21s 597us/step - loss: 0.6078 - weighted_acc: 0.6810\n",
      "11598/11598 [==============================] - 3s 222us/step\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.814054 \n",
      "\n",
      "*** New High Score (previous: 0.795600) \n",
      "\n",
      "Epoch 4/100\n",
      "34793/34793 [==============================] - 21s 597us/step - loss: 0.5804 - weighted_acc: 0.7070\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.825998 \n",
      "\n",
      "*** New High Score (previous: 0.814054) \n",
      "\n",
      "Epoch 5/100\n",
      "34793/34793 [==============================] - 21s 597us/step - loss: 0.5570 - weighted_acc: 0.7346\n",
      "11598/11598 [==============================] - 3s 225us/step\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.834878 \n",
      "\n",
      "*** New High Score (previous: 0.825998) \n",
      "\n",
      "Epoch 6/100\n",
      "34793/34793 [==============================] - 21s 606us/step - loss: 0.5440 - weighted_acc: 0.7415\n",
      "11598/11598 [==============================] - 3s 222us/step\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.839834 \n",
      "\n",
      "*** New High Score (previous: 0.834878) \n",
      "\n",
      "Epoch 7/100\n",
      "34793/34793 [==============================] - 21s 596us/step - loss: 0.5267 - weighted_acc: 0.7506\n",
      "11598/11598 [==============================] - 3s 220us/step\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.842327 \n",
      "\n",
      "*** New High Score (previous: 0.839834) \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "34793/34793 [==============================] - 21s 595us/step - loss: 0.5304 - weighted_acc: 0.7552\n",
      "11598/11598 [==============================] - 3s 220us/step\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.844512 \n",
      "\n",
      "*** New High Score (previous: 0.842327) \n",
      "\n",
      "Epoch 9/100\n",
      "34793/34793 [==============================] - 21s 596us/step - loss: 0.5062 - weighted_acc: 0.7620\n",
      "11598/11598 [==============================] - 3s 222us/step\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.846549 \n",
      "\n",
      "*** New High Score (previous: 0.844512) \n",
      "\n",
      "Epoch 10/100\n",
      "34793/34793 [==============================] - 21s 601us/step - loss: 0.5035 - weighted_acc: 0.7724\n",
      "11598/11598 [==============================] - 3s 220us/step\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.846326 \n",
      "\n",
      "Epoch 11/100\n",
      "34793/34793 [==============================] - 21s 595us/step - loss: 0.4873 - weighted_acc: 0.7793\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.847741 \n",
      "\n",
      "*** New High Score (previous: 0.846549) \n",
      "\n",
      "Epoch 12/100\n",
      "34793/34793 [==============================] - 21s 597us/step - loss: 0.4909 - weighted_acc: 0.7703\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.849644 \n",
      "\n",
      "*** New High Score (previous: 0.847741) \n",
      "\n",
      "Epoch 13/100\n",
      "34793/34793 [==============================] - 21s 596us/step - loss: 0.4572 - weighted_acc: 0.7997\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 13 - score: 0.847996 \n",
      "\n",
      "Epoch 14/100\n",
      "34793/34793 [==============================] - 21s 596us/step - loss: 0.4512 - weighted_acc: 0.8114\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 14 - score: 0.843663 \n",
      "\n",
      "Epoch 15/100\n",
      "34793/34793 [==============================] - 21s 598us/step - loss: 0.4348 - weighted_acc: 0.8179\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 15 - score: 0.836482 \n",
      "\n",
      "Epoch 16/100\n",
      "34793/34793 [==============================] - 21s 597us/step - loss: 0.4277 - weighted_acc: 0.8131\n",
      "11598/11598 [==============================] - 3s 221us/step\n",
      "\n",
      " ROC-AUC - epoch: 16 - score: 0.833356 \n",
      "\n",
      "Epoch 00015: early stopping, high score = 0.849644\n",
      "Epoch 1/100\n",
      "34794/34794 [==============================] - 22s 623us/step - loss: 0.6642 - weighted_acc: 0.6023\n",
      "11597/11597 [==============================] - 3s 232us/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.743556 \n",
      "\n",
      "*** New High Score (previous: 0.000000) \n",
      "\n",
      "Epoch 2/100\n",
      "34794/34794 [==============================] - 21s 603us/step - loss: 0.6095 - weighted_acc: 0.6588\n",
      "11597/11597 [==============================] - 3s 228us/step\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.771298 \n",
      "\n",
      "*** New High Score (previous: 0.743556) \n",
      "\n",
      "Epoch 3/100\n",
      "34794/34794 [==============================] - 21s 617us/step - loss: 0.5640 - weighted_acc: 0.7035\n",
      "11597/11597 [==============================] - 3s 220us/step\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.795931 \n",
      "\n",
      "*** New High Score (previous: 0.771298) \n",
      "\n",
      "Epoch 4/100\n",
      "34794/34794 [==============================] - 21s 599us/step - loss: 0.5549 - weighted_acc: 0.7056\n",
      "11597/11597 [==============================] - 3s 230us/step\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.807042 \n",
      "\n",
      "*** New High Score (previous: 0.795931) \n",
      "\n",
      "Epoch 5/100\n",
      "34794/34794 [==============================] - 21s 603us/step - loss: 0.5385 - weighted_acc: 0.7260\n",
      "11597/11597 [==============================] - 3s 223us/step\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.814100 \n",
      "\n",
      "*** New High Score (previous: 0.807042) \n",
      "\n",
      "Epoch 6/100\n",
      "34794/34794 [==============================] - 21s 593us/step - loss: 0.5214 - weighted_acc: 0.7364\n",
      "11597/11597 [==============================] - 3s 217us/step\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.816888 \n",
      "\n",
      "*** New High Score (previous: 0.814100) \n",
      "\n",
      "Epoch 7/100\n",
      "34794/34794 [==============================] - 21s 604us/step - loss: 0.5228 - weighted_acc: 0.7243\n",
      "11597/11597 [==============================] - 3s 222us/step\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.824511 \n",
      "\n",
      "*** New High Score (previous: 0.816888) \n",
      "\n",
      "Epoch 8/100\n",
      "34794/34794 [==============================] - 21s 608us/step - loss: 0.5047 - weighted_acc: 0.7570\n",
      "11597/11597 [==============================] - 3s 218us/step\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.825295 \n",
      "\n",
      "*** New High Score (previous: 0.824511) \n",
      "\n",
      "Epoch 9/100\n",
      "34794/34794 [==============================] - 21s 594us/step - loss: 0.4952 - weighted_acc: 0.7555\n",
      "11597/11597 [==============================] - 3s 218us/step\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.827850 \n",
      "\n",
      "*** New High Score (previous: 0.825295) \n",
      "\n",
      "Epoch 10/100\n",
      "34794/34794 [==============================] - 21s 602us/step - loss: 0.4886 - weighted_acc: 0.7668\n",
      "11597/11597 [==============================] - 3s 219us/step\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.828568 \n",
      "\n",
      "*** New High Score (previous: 0.827850) \n",
      "\n",
      "Epoch 11/100\n",
      "34794/34794 [==============================] - 21s 599us/step - loss: 0.4656 - weighted_acc: 0.7759\n",
      "11597/11597 [==============================] - 3s 219us/step\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.828515 \n",
      "\n",
      "Epoch 12/100\n",
      "34794/34794 [==============================] - 21s 600us/step - loss: 0.4599 - weighted_acc: 0.7756\n",
      "11597/11597 [==============================] - 3s 219us/step\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.831820 \n",
      "\n",
      "*** New High Score (previous: 0.828568) \n",
      "\n",
      "Epoch 13/100\n",
      "34794/34794 [==============================] - 21s 610us/step - loss: 0.4474 - weighted_acc: 0.7928\n",
      "11597/11597 [==============================] - 3s 224us/step\n",
      "\n",
      " ROC-AUC - epoch: 13 - score: 0.829019 \n",
      "\n",
      "Epoch 14/100\n",
      "34794/34794 [==============================] - 21s 599us/step - loss: 0.4333 - weighted_acc: 0.7977\n",
      "11597/11597 [==============================] - 3s 225us/step\n",
      "\n",
      " ROC-AUC - epoch: 14 - score: 0.828238 \n",
      "\n",
      "Epoch 15/100\n",
      "34794/34794 [==============================] - 21s 597us/step - loss: 0.4142 - weighted_acc: 0.7999\n",
      "11597/11597 [==============================] - 3s 223us/step\n",
      "\n",
      " ROC-AUC - epoch: 15 - score: 0.821582 \n",
      "\n",
      "Epoch 16/100\n",
      "34794/34794 [==============================] - 21s 610us/step - loss: 0.3932 - weighted_acc: 0.8201\n",
      "11597/11597 [==============================] - 3s 223us/step\n",
      "\n",
      " ROC-AUC - epoch: 16 - score: 0.812894 \n",
      "\n",
      "Epoch 00015: early stopping, high score = 0.831820\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Model:' , nn_arch)\n",
    "model = get_model()\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# Used epochs=100 with early exiting for best score.\n",
    "epochs = 100\n",
    "gc.collect()\n",
    "K.clear_session()\n",
    "\n",
    "# Change to 4\n",
    "num_folds = 4 #number of folds\n",
    "\n",
    "#Приводим типы\n",
    "y = np.array(y)\n",
    "\n",
    "#Веса примеров, \"меняем местами\" 1 и 0\n",
    "w_0 = 1/np.sum((y == 0.0).astype('float'))\n",
    "w_1 = 1/np.sum((y == 1.0).astype('float'))\n",
    "w = w_0*(y == 0.0).astype('float') + w_1*(y == 1.0).astype('float')\n",
    "w /= np.sum(w)\n",
    "w *= len(y)\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=239)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "    y_train = y[train_index] \n",
    "    y_test  = y[test_index]\n",
    "    \n",
    "    X_train = X_seq_pad[train_index]\n",
    "    X_test  = X_seq_pad[test_index]\n",
    "    \n",
    "    w_train = w[train_index]\n",
    "    w_test  = w[test_index]\n",
    "    \n",
    "    model = get_model()\n",
    "    \n",
    "    ra_val = RocAucEvaluation(validation_data=(X_test, y_test, w_test), interval = 1, cv_iter=i, arch=nn_arch)\n",
    "    \n",
    "    model.fit(X_train, y_train, sample_weight=w_train, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "             callbacks = [ra_val])\n",
    "    gc.collect()\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46391/46391 [==============================] - 13s 288us/step\n",
      "46391/46391 [==============================] - 13s 291us/step\n",
      "46391/46391 [==============================] - 14s 295us/step\n"
     ]
    }
   ],
   "source": [
    "y_all = load_model('models/best_model_1_0.h5').predict(X_seq_pad, verbose=1, batch_size=512)\n",
    "#y_all += load_model('models/best_model_1_1.h5').predict(X_seq_pad, verbose=1, batch_size=512)\n",
    "y_all += load_model('models/best_model_1_2.h5').predict(X_seq_pad, verbose=1, batch_size=512)\n",
    "y_all += load_model('models/best_model_1_3.h5').predict(X_seq_pad, verbose=1, batch_size=512)\n",
    "y_all /= 3.0#2.0*np.average(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Scores ====\n",
      "   Acc: 0.9662650082990235\n",
      "  Prec: 0.15826330532212884\n",
      "Recall: 0.3837011884550085\n",
      "    F1: 0.22409519087754093\n",
      "RocAuc: 0.6787288964850476\n",
      "================\n",
      "FP: 1202.0\n",
      "FN: 363.0\n",
      "TP: 226.0\n",
      "TN: 44600.0\n",
      "N:  46391\n"
     ]
    }
   ],
   "source": [
    "#y_t = (y_all>1.0*np.average(y_all)).astype('float').reshape(y.shape)\n",
    "y_t = (y_all>0.8).astype('float').reshape(y.shape)\n",
    "\n",
    "#print('==== Weghtted scores ====')\n",
    "#print('   Acc:', accuracy_score(y, y_t, sample_weight=w))\n",
    "#print('  Prec:', precision_score(y, y_t, sample_weight=w))\n",
    "#print('Recall:', recall_score(y, y_t, sample_weight=w))\n",
    "#print('    F1:', f1_score(y, y_t, sample_weight=w))\n",
    "#print('RocAuc:', roc_auc_score(y, y_t, sample_weight=w))\n",
    "\n",
    "print('==== Scores ====')\n",
    "print('   Acc:', accuracy_score(y, y_t))\n",
    "print('  Prec:', precision_score(y, y_t))\n",
    "print('Recall:', recall_score(y, y_t))\n",
    "print('    F1:', f1_score(y, y_t))\n",
    "print('RocAuc:', roc_auc_score(y, y_t))\n",
    "\n",
    "print('================')\n",
    "print('FP:', np.sum((y_t != y).astype('float')*y_t))\n",
    "print('FN:', np.sum((y_t != y).astype('float')*y))\n",
    "print('TP:', np.sum((y_t == y).astype('float')*y_t))\n",
    "print('TN:', np.sum((y_t == y).astype('float')*(1-y)))\n",
    "print('N: ', len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Class</th>\n",
       "      <th>Use</th>\n",
       "      <th>WrdCnt</th>\n",
       "      <th>TokCnt</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>46391.000000</td>\n",
       "      <td>46391.000000</td>\n",
       "      <td>46391.000000</td>\n",
       "      <td>46391.000000</td>\n",
       "      <td>46391.000000</td>\n",
       "      <td>46391.000000</td>\n",
       "      <td>46391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.039318</td>\n",
       "      <td>0.170637</td>\n",
       "      <td>0.012696</td>\n",
       "      <td>21.470285</td>\n",
       "      <td>21.396844</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.518805</td>\n",
       "      <td>1.543905</td>\n",
       "      <td>0.111962</td>\n",
       "      <td>32.077247</td>\n",
       "      <td>31.949034</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.015397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2053.000000</td>\n",
       "      <td>2050.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Score         Class           Use        WrdCnt        TokCnt  \\\n",
       "count  46391.000000  46391.000000  46391.000000  46391.000000  46391.000000   \n",
       "mean      -0.039318      0.170637      0.012696     21.470285     21.396844   \n",
       "std        0.518805      1.543905      0.111962     32.077247     31.949034   \n",
       "min      -20.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      7.000000      7.000000   \n",
       "50%        0.000000      0.000000      0.000000     13.000000     13.000000   \n",
       "75%        0.000000      0.000000      0.000000     25.000000     25.000000   \n",
       "max        0.000000     17.000000      1.000000   2053.000000   2050.000000   \n",
       "\n",
       "                 FN            FP  \n",
       "count  46391.000000  46391.000000  \n",
       "mean       0.012524      0.000237  \n",
       "std        0.111209      0.015397  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max        1.000000      1.000000  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FN'] = y*(y_t != y).astype('float')\n",
    "df['FP'] = y_t*(y_t != y).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp = df[df['FP'] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Class</th>\n",
       "      <th>Use</th>\n",
       "      <th>WrdCnt</th>\n",
       "      <th>TokCnt</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1202.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>1202.000000</td>\n",
       "      <td>1202.000000</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>1202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.122296</td>\n",
       "      <td>19.948419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.058869</td>\n",
       "      <td>26.798828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score   Class     Use       WrdCnt       TokCnt      FN      FP\n",
       "count  1202.0  1202.0  1202.0  1202.000000  1202.000000  1202.0  1202.0\n",
       "mean      0.0     0.0     0.0    20.122296    19.948419     0.0     1.0\n",
       "std       0.0     0.0     0.0    27.058869    26.798828     0.0     0.0\n",
       "min       0.0     0.0     0.0     1.000000     1.000000     0.0     1.0\n",
       "25%       0.0     0.0     0.0     6.000000     6.000000     0.0     1.0\n",
       "50%       0.0     0.0     0.0    12.000000    12.000000     0.0     1.0\n",
       "75%       0.0     0.0     0.0    23.000000    23.000000     0.0     1.0\n",
       "max       0.0     0.0     0.0   336.000000   338.000000     0.0     1.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp.to_pickle('data/Xy_fp.pkl')\n",
    "df_fp.to_excel('data/Xy_fp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn = df[df['FN'] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn.to_pickle('data/Xy_fn.pkl')\n",
    "df_fn.to_excel('data/Xy_fn.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
